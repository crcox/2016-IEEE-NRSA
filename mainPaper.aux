\relax 
\citation{RSA}
\citation{searchlight}
\citation{similarity}
\citation{RSA,searchlight}
\citation{RSA,searchlight}
\citation{RSA}
\citation{searchlight}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Representational Similarity Analysis. Traditional RSA methods consider only localized brain networks, such as specific regions of interest or spherical clusters of the cortex (upper left) \cite  {RSA,searchlight}. We propose a new {\em  Network} RSA (NRSA) method that can potentially identify non-local brain networks that encode similarity information (lower left). Within a set of voxels $\Omega $ (localized or non-local), the correlations between the activation patterns resulting from different stimuli approximate (perceptual) similarities between the stimuli. \relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:WRSA}{{1}{1}}
\newlabel{fig.fitting}{{1}{1}}
\citation{maryam}
\citation{obo11,lounici,vandegeer}
\citation{obo11,lounici,vandegeer}
\citation{EN}
\citation{oscar}
\citation{owl}
\@writefile{toc}{\contentsline {section}{\numberline {II}Learning Similarity Encodings \\ via Group Lasso}{2}}
\newlabel{eqn.grouplasso}{{2}{2}}
\citation{owl}
\citation{oscar}
\citation{owl}
\citation{owl}
\citation{owl}
\@writefile{toc}{\contentsline {section}{\numberline {III}GrOWL}{3}}
\newlabel{Sec:growl}{{III}{3}}
\newlabel{eqn:L1}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}GrOWL penalty}{3}}
\newlabel{Eqn:growl}{{4}{3}}
\newlabel{lemma1}{{III.1}{3}}
\newlabel{ident1}{{III.1}{3}}
\newlabel{thm2}{{III.2}{3}}
\newlabel{thm3}{{III.3}{3}}
\citation{prox}
\citation{candes13}
\citation{ZengFigueiredo2014}
\citation{PlautETAL96,HarmSeidenberg04}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Proximal algorithms}{4}}
\newlabel{proxG}{{5}{4}}
\newlabel{Vhat}{{6}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Network RSA: Simulated Data}{4}}
\newlabel{wbrsa1}{{IV}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A comparison of group lasso and grOWL optimization solutions with correlated columns in $\bm  {X}$ showing that GrOWL-I and GrOWL-II select relevant features (row 5 and 7) even if they happen to be strongly correlated and automatically cluster them by setting the corresponding coefficient rows to be equal (or nearly equal).\relax }}{4}}
\newlabel{Fig:sim}{{2}{4}}
\citation{RSA}
\citation{similarity}
\citation{antani02}
\@writefile{toc}{\contentsline {section}{\numberline {V}Network RSA: Real Data}{5}}
\newlabel{wbrsa2}{{V}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top panel: Network architecture (left) and the similarity structure expressed in each layer (right). Red background shows the direct pathway and blue the indrect pathway from orthography to phonology. Layers in the two pathways encode different similarity structures. The target similarity matrices for the analysis express either the semantic structure (top layer) or the phonological structure (bottom right layer). Arrows indicate feed-forward connectivity. Bottom panel: Units selected by group LASSO (right) and GrOWL (middle) when decoding semantic (top) or phonological (bottom) structure. Colors show the proportion of times across subjects and unit concatenations that the unit received a non-zero weight, with red indicating 1 and gray 0. The rightmost plots show the largest weights in the associated matrix W for each GrOWL model, which pick out two subnetworks in the model.\relax }}{6}}
\newlabel{fig.network}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}fMRI dataset}{6}}
\newlabel{fig_first_case}{{4a}{7}}
\newlabel{sub@fig_first_case}{{(a)}{a}}
\newlabel{fig_second_case}{{4b}{7}}
\newlabel{sub@fig_second_case}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces ROC curves generated by sweeping through $\lambda $ values (for $\lambda = 0$, all units are selected and as $\lambda $ is increased fewer units are given non-zero weight). Each curve represents a fixed value of $\lambda _1$, where the curve $\lambda _1 = 0$ corresponds to group lasso. ROC curves are averaged across participants for each method, considering both similarity structures, Semantics (left panel) and Phonology (right panel).\relax }}{7}}
\newlabel{fig.roc}{{4}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Results}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}}
\newlabel{fig_first_case}{{5a}{8}}
\newlabel{sub@fig_first_case}{{(a)}{a}}
\newlabel{fig_second_case}{{5b}{8}}
\newlabel{sub@fig_second_case}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Panel (a) shows mean hold-out prediction error for group lasso and GrOWLs for 23 subjects. Panel (b) shows surface maps corresponding to group lasso (left), GrOWL-I (middle) and GrOWL-II (right) showing the voxels selected for \textit  {at least five} and \textit  {all nine} cross-validations in the top and bottom rows respectively. The heat map shows the number of subjects for which those voxels were picked. Blue is the least (1 subject) and red is the most (10 or more subjects).\relax }}{8}}
\newlabel{fig.error}{{5}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Network plot showing the top edges from the $\bm  {W}$ matrix for the best-performing parameterization of group LASSO (top) and GrOWL-II (bottom) in one subject. The thickness of the edges is proportional to the edge weights.\relax }}{8}}
\newlabel{fig.NW}{{6}{8}}
\@writefile{toc}{\contentsline {section}{Appendix\nobreakspace  A: Clustering properties of GrOWL with absolute error loss function}{8}}
\@writefile{toc}{\contentsline {section}{Appendix\nobreakspace  B: Clustering properties of GrOWL with squared Frobenius loss function}{9}}
\newlabel{eqn:L2}{{7}{9}}
\bibcite{RSA}{1}
\bibcite{searchlight}{2}
\bibcite{multitask1}{3}
\bibcite{similarity}{4}
\bibcite{PlautETAL96}{5}
\bibcite{obo11}{6}
\bibcite{oscar}{7}
\bibcite{Dalton}{8}
\bibcite{EN}{9}
\bibcite{lounici}{10}
\bibcite{vandegeer}{11}
\bibcite{candes13}{12}
\bibcite{bogdan2014}{13}
\bibcite{HarmSeidenberg04}{14}
\bibcite{owl}{15}
\bibcite{prox}{16}
\bibcite{buhlmann13}{17}
\bibcite{antani02}{18}
\bibcite{maryam}{19}
\bibcite{ZengFigueiredo2013}{20}
\bibcite{ZengFigueiredo2014}{21}
\@writefile{toc}{\contentsline {section}{Appendix\nobreakspace  C: Proximal algorithms for GrOWL}{10}}
\@writefile{toc}{\contentsline {section}{References}{10}}
