
%% bare_jrnl.tex
%% V1.4a
%% 2014/09/17
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8a or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_conf_compsoc.tex,
%%                    bare_jrnl_compsoc.tex, bare_jrnl_transmag.tex
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices and paper sizes can       ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/


\documentclass[journal]{IEEEtran}

\input{packages.tex}
\usepackage{subfig}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
	\title{Brain Networks and Representational Similarity Analysis via Sparse Multitask Regression}
	
	
	\author{Urvashi~Oswal,
		Christopher~Cox,
		Matthew~A.~Lambon~Ralph,
		Timothy~Rogers,
		and~Robert~Nowak,~\IEEEmembership{Fellow~IEEE}% <-this % stops a space
	\thanks{U. Oswal and R. Nowak are with the Department of Electrical and Computer Engineering, University of Wisconsin-Madison, WI, 53706 USA. e-mail: uoswal@wisc.edu, nowak@ece.wisc.edu}% <-this % stops a space
	\thanks{C. Cox and T. Rogers are with the Department of Psychology, University of Wisconsin-Madison, WI, 53706 USA. e-mail: \{crcox, ttrogers\}@wisc.edu}% <-this % stops a space
	\thanks{M. Lambon Ralph is with the Neuroscience and Aphasia Research Unit (NARU), School of Psychological Sciences, University of Manchester, Manchester M13 9PL, UK. email: matt.lambon-ralph@manchester.ac.uk}}%
	%\thanks{Manuscript received April 19, 2005; revised September 17, 2014.}}
	
	
	% The paper headers
	%\markboth{Journal of \LaTeX\ Class Files,~Vol.~XX, No.~XX, September~2014}%
	%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
	% The only time the second header will appear is for the odd numbered pages
	% after the title page when using the twoside option.
	% 
	% *** Note that you probably will NOT want to include the author's ***
	% *** name in the headers of peer review papers.                   ***
	% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
	% you desire.
	
	
	
	
	% If you want to put a publisher's ID mark on the page you can do it like
	% this:
	%\IEEEpubid{0000--0000/00\$00.00~\copyright~2014 IEEE}
	% Remember, if you use this you must call \IEEEpubidadjcol in the second
	% column for its text to clear the IEEEpubid mark.
	
	
	
	% use for special paper notices
	%\IEEEspecialpapernotice{(Invited Paper)}
	
	
	
	
	% make the title area
	\maketitle
	
	% As a general rule, do not put math, special symbols or citations
	% in the abstract or keywords.
	\begin{abstract}
		\input{abstract.tex}
	\end{abstract}
	
	% Note that keywords are not normally used for peerreview papers.
	%\begin{IEEEkeywords}
	%	Multi-task learning, %IEEEtran, journal, \LaTeX, paper, template.
	%\end{IEEEkeywords}
	
	\IEEEpeerreviewmaketitle
	
	
	
	\section{Introduction}
	\input{intro.tex}
	
	\section{GrOWL}
	\label{Sec:growl}
	\input{growl.tex}
	
	\section{Network RSA: Simulated Data}
        \label{wbrsa1}
	\input{simulation.tex}
	
	\section{Network RSA: Real Data}
        \label{wbrsa2}
	\input{application.tex}
	
	\section{Conclusion}
%We have developed and demonstrated a new approach for whole-brain Representational Similarity Analysis called Network RSA (NRSA). Unlike traditional RSA methods that consider only specific regions of interest or spherical clusters of the cortex,  NRSA can discover arbitrarily structured brain networks (possibly widely distributed and non-local) that encode similarity information.  NRSA is posed as a sparsity-regularized multi-task regression problem. This allows us to effectively search over all subsets of voxels (not just localized clusters) to detect similarity-encoding networks.  We proposed a new sparsity regularizer for multi-task regression that is able to cope with strongly correlated covariates (voxels in the fMRI application), which can perform better than the conventional group lasso. named the GrOWL.  Experiments with real and synthetic datasets demonstrated the potential of our new approach.
	
We have developed and demonstrated a new approach for whole-brain Representational Similarity Analysis called Network RSA (NRSA). Unlike traditional RSA methods that consider only specific regions of interest or spherical clusters of the cortex,  NRSA can discover arbitrarily structured brain networks (possibly widely distributed and non-local) that encode similarity information.  NRSA is posed as a sparsity-regularized multi-task regression problem. This allows us to effectively search over all subsets of voxels (not just localized clusters) to detect similarity-encoding networks.  We further proposed a new sparsity regularizer for multi-task regression, the GrOWL, that is able to cope with strongly correlated covariates, a serious challenge for sparsity-based approaches to fMRI analysis. 

Our analysis of synthetic data generated from a neural network model of word-reading showed that the GrOWL identifies signal-carrying features more consistently than group lasso when signal is redundant; that the approach can discover different feature subsets encoding different kinds of similarity structure; and that the weight matrix $\bW$ can be used to uncover subnetworks of features that jointly work to encode such structure. Analysis of visual similarity structure in fMRI data from a picture-viewing task further established that the approach can be used to find cortical regions and subnetworks that likewise express a target similarity structure. In future work these methods may be useful for discovering such structure for cases where the interesting cortical regions and networks have proven elusive.

	\appendices
	
	\section{Clustering properties of GrOWL with absolute error loss function}
	\input{supplement1.tex}
	
	\section{Clustering properties of GrOWL with squared Frobenius loss function}
	\input{supplement.tex}
	
	\section{Proximal algorithms for GrOWL}
	\input{supplement2.tex}
	% you can choose not to have a title for an appendix
	% if you want by leaving the argument blank
	

	
	
	% use section* for acknowledgment
	%\section*{Acknowledgment}
	
	
	%The authors would like to thank...
	
	
	% Can use something like this to put references on a page
	% by themselves when using endfloat and the captionsoff option.
	%\ifCLASSOPTIONcaptionsoff
	%\newpage
	%\fi
	
	
	
	% trigger a \newpage just before the given reference
	% number - used to balance the columns on the last page
	% adjust value as needed - may need to be readjusted if
	% the document is modified later
	%\IEEEtriggeratref{8}
	% The "triggered" command can be changed if desired:
	%\IEEEtriggercmd{\enlargethispage{-5in}}
	
	% references section
	
	% can use a bibliography generated by BibTeX as a .bbl file
	% BibTeX documentation can be easily obtained at:
	% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
	% The IEEEtran BibTeX style support page is at:
	% http://www.michaelshell.org/tex/ieeetran/bibtex/
	%\bibliographystyle{IEEEtran}
	% argument is your BibTeX string definitions and bibliography database(s)
	%\bibliography{IEEEabrv,../bib/paper}
	%
	% <OR> manually copy in the resultant .bbl file
	% set second argument of \begin to the number of references
	% (used to reserve space for the reference number labels box)
	\begin{thebibliography}{20}
		
		%\bibitem{IEEEhowto:kopka}
		%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
	%	0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
		
		\bibitem{RSA} N.~Kriegeskorte, M.~Mur, and P.~Bandettini, ``Representational similarity analysis--connecting the branches of systems neuroscience", \emph{Frontiers in systems neuroscience}, 2, 2008.
			\bibitem{searchlight} N.~Kriegeskorte, R.~Goebel, and P.~Bandettini,  ``Information-based functional brain mapping", \emph{Proceedings of the National Academy of Sciences of the United States of America, 103} vol.~10, pp.~3863--3868, 2006.
		
	
		\bibitem{multitask1} A.~Argyriou, T.~Evgeniou, and M.~Pontil. ``Convex multi-task feature learning",  \emph{Machine Learning, 3},
vol.~73,, pp.~243--272, 2008.
		
		\bibitem{similarity}A.~Tversky, and I.~Gati, ``Similarity, separability, and the triangle inequality", \emph{Psychological review, 2} vol.~89, pp.~123, 1982.
		
		\bibitem{PlautETAL96}
		D.~Plaut, J.~McClelland, M.~Seidenberg, and K.~Patterson, ``Understanding normal and impaired word reading: computational principles in quasi-regular domains." {\em Psychological review 1} vol.~103, pp.~56, 1996.
		
		\bibitem{obo11}
		G.~Obozinski, M.~Wainwright and M.~Jordan, ``Support union recovery in high-dimensional multivariate regression," {\it Ann. Stat.}, pp.~1--47, 2011.
		
		\bibitem{oscar}
		H.~Bondell and B.~Reich, ``Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR," {\it Biometrics}, vol.~64, pp.~115--123, 2007.
		
		
		\bibitem{Dalton}
		H.~Dalton, ``The measurement of the inequality of incomes," {\it The Economic Journal}, vol.~30, pp.~348--361, 1920.
		
		
		%\bibitem{smart}H.~Wang, F.~Nie, H.~Huang, S.~Risacher, C.~Ding, A.~Saykin, and L.~Shen, ``Sparse multi-task regression and feature selection to identify brain imaging predictors for memory performance", \emph{IEEE International Conference on Computer Vision (ICCV)}, pp.~557--562, 2011.
		
		
		\bibitem{EN}H.~Zou, and T.~Hastie, ``Regularization and variable selection via the elastic net. \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology), 67} vol.~2, pp.~301--320, 2005
		
		\bibitem{lounici} K.~Lounici, M.~Pontil, A.~Tsybakov, and S.~van de Geer. ``Taking advantage of sparsity in multi-task learning." \url{http://arxiv.org/abs/0903.1468}, 2009.
		
		\bibitem{vandegeer} K.~Lounici, M.~Pontil, S.~van de Geer, and A.~Tsybakov, ``Oracle inequalities and optimal inference under group sparsity", \emph{The Annals of Statistics, 39} vol.~4, pp.~2164--2204, 2012.
		
		
		\bibitem{candes13}
		M.~Bogdan, E.~van den Berg, W.~Su, and E.~Cand\`{e}s, ``Statistical estimation and testing via the sorted $\ell_1$ norm,''  available at \url{http://arxiv.org/abs/1310.1969}, 2013.
		
		\bibitem{bogdan2014}
		M.~Bogdan, E.~van~den~Berg, C.~Sabatti, W.~Su, and E.~Cand\`{e}s, ``SLOPE -- adaptive variable selection via convex optimization", available at \url{http://arxiv.org/abs/1407.3824}, 2014.
		
		\bibitem{HarmSeidenberg04}
		M.~Harm, and M.~Seidenberg, ``Computing the meanings of words in reading: cooperative division of labor between visual and phonological processes." {\em Psychological review 3}, vol.~111, pp.~662, 2004.
		
		\bibitem{owl} M.~Figueiredo, and R.~Nowak, ``Sparse Estimation with Strongly Correlated Variables using Ordered Weighted l1 Regularization", \url{http://arxiv.org/abs/1409.4005}, 2014.
		
		\bibitem{prox} N.~Parikh, and S.~Boyd, ``Proximal algorithms.", {\em Foundations and Trends in optimization 3} vol.~1, pp.~123--231, 2013.
		
		\bibitem{buhlmann13}
		P.~B\"{u}hlmann, P.~R\"{u}ttiman, S.~van~de~Geer, and C.-H.~Zhang, ``Correlated variables in regression: Clustering and sparse estimation,'' {\em Journal of Statistical Planning and Inference}, pp.~1835--1858, 2013.
		
		%\bibitem{prox}
		%P.~Combettes, \fix D.~D{\~u}ng, and B.~V{\~u}, "Proximity for sums of composite functions",\emph{Journal of Mathematical Analysis and applications, 380} vol.~2, pp.~680--688, 2011.
		\bibitem{antani02}
		S.~Antani, R.~Kasturi, and R.~Jain, ``A survey on the use of pattern recognition methods for abstraction, indexing and retrieval of images and video," {\em Pattern recognition 4} vol.~35, pp.~945--965, 2002.
		
		\bibitem{maryam} S.~Oymak, A.~Jalali, M.~Fazel, Y.~Eldar, and B.~Hassibi, ``Simultaneously structured models with application to sparse and low-rank matrices", \url{http://arxiv.org/abs/1212.3753}, 2012.
		
		\bibitem{ZengFigueiredo2013}
		X.~Zeng, M.~Figueiredo, ``Decreasing Weighted Sorted $\ell_1$ Regularization", {\em IEEE Signal Processing Letters,} vol.~21, pp.~1240--1244, 2014.
		
		\bibitem{ZengFigueiredo2014}
		X.~Zeng, M.~Figueiredo, ``The atomic norm formulation of OSCAR regularization with application to the Frank-Wolfe algorithm", {\em Proceedings of the European Signal Processing Conference}, Lisbon, Portugal, 2014.
		
		
		
	\end{thebibliography}
	
	% biography section
	% 
	% If you have an EPS/PDF photo (graphicx package needed) extra braces are
	% needed around the contents of the optional argument to biography to prevent
	% the LaTeX parser from getting confused when it sees the complicated
	% \includegraphics command within an optional argument. (You could create
	% your own custom macro containing the \includegraphics command to make things
	% simpler here.)
	%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
	% or if you just want to reserve a space for a photo:
	
	%\begin{IEEEbiography}{Michael Shell}
	%Biography text here.
	%\end{IEEEbiography}
	
	% if you will not have a photo at all:
	%\begin{IEEEbiographynophoto}{John Doe}
	%Biography text here.
	%\end{IEEEbiographynophoto}
	
	% insert where needed to balance the two columns on the last page with
	% biographies
	%\newpage
	
	%\begin{IEEEbiographynophoto}{Jane Doe}
	%Biography text here.
	%\end{IEEEbiographynophoto}
	
	% You can push biographies down or up by placing
	% a \vfill before or after them. The appropriate
	% use of \vfill depends on what kind of text is
	% on the last page and whether or not the columns
	% are being equalized.
	
	%\vfill
	
	% Can be used to pull up biographies so that the bottom of the last one
	% is flush with the other column.
	%\enlargethispage{-5in}
	
	
	
	% that's all folks
\end{document}




